<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
  <link href="//gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.58.0" />

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Automate Prometheus Alerts in Kubernetes &middot; Pawel Grzesik</title>

  
  <link type="text/css" rel="stylesheet" href="https://wolfedale.github.io/css/print.css" media="print">
  <link type="text/css" rel="stylesheet" href="https://wolfedale.github.io/css/poole.css">
  <link type="text/css" rel="stylesheet" href="https://wolfedale.github.io/css/syntax.css">
  <link type="text/css" rel="stylesheet" href="https://wolfedale.github.io/css/hyde.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700">


  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.png">

  
  
</head>

  <body class=" ">
  <aside class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="https://wolfedale.github.io/"><h1>Pawel Grzesik</h1></a>
      <p class="lead">
       SRE at eBay, love to code in Golang and spending too much time on the shooting range. 
      </p>
    </div>

    <nav>
      <ul class="sidebar-nav">
        <li><a href="https://wolfedale.github.io/">Home</a> </li>
        <li><a href="http://github.com/wolfedale/"> Github </a></li><li><a href="https://www.linkedin.com/in/pawel-grzesik-45766420/"> LinkedIn </a></li><li><a href="https://twitter.com/GrzesikPawel"> Twitter </a></li>
      </ul>
    </nav>

    <p>&copy; 2020. All rights reserved. </p>
  </div>
</aside>

    <main class="content container">
    <div class="post">
  <h1>Automate Prometheus Alerts in Kubernetes</h1>
  <time datetime=2019-12-06T19:41:16&#43;0100 class="post-date">Fri, Dec 6, 2019</time>
  

<p>To keep monitoring rules up to date it&rsquo;s not an easy task. Especially when we are running a lot of services, or when we are growing too fast. There is few ways how we can handle it. For example we can use pipelines and add new monitoring rules to every new service we are deploying. Depends on our piplines and size of services, it might be easy or not. In my case this method worked at the beginning, later on I started to have issues. At some point it startd to be more and more complicated and more time consuming. Another problem which I hit was that whenever I wanted to change something at my rules globally I needed to do it for all the repositories. And again when we hit some number of services, this trivial task might be not so easy to finish. This is why I started to work on the Prometheus Alerter Rules Generator operator, running inside of each cluster and watching for the new ingresses and services.</p>

<p>Now let&rsquo;s look on some terminology.</p>

<ul>
<li><p><em>SLI</em> - Service Level Indicator, is a measurement the service provider uses for the goal. Frequency of successful probes of our system. For example: 95th percentile latency of homepage requests over past 5 minutes &lt; 300ms, or percentile of HTTP responses which are successful (200), out of all 20x and 50x HTTP responses over past 5 minutes</p></li>

<li><p><em>SLO</em> - Service Level Objectives, are service level objectices, which are agreed upon bounds for how often those SLIs must be met. SLO lets you specify how much downtime your service can have in a given period. For example 95th percentile homepage SLI will succeed 99.9% over trailing year or 43 minutes every 30 days for a service that needs to be available 99.9% of the time. This downtime is also your error budget.</p></li>

<li><p><em>SLA</em> - Service Level Agreements, are business level agreemenets, which define the service availability for a customer and the penalties for failing to deliver that availability.</p></li>

<li><p>Error Budget provides a clear, objective metric that determines how unreliable the service is allowed to be within a single quarter.</p></li>
</ul>

<p>And of course Four Golden Signals which are: latency, traffic, errors, saturation.</p>

<p>There is no point to go here for more details, if you like to read about them the best resource will be to check book Site Reliability Engineering: How Google Runs Production Systems. It&rsquo;s a really good resource about how to monitor your infrastructure. It will not always fit to what you are doing but I believe it can help a lot.</p>

<p>So how my operator is working.</p>

<ul>
<li><p>it&rsquo;s keeping all data in memory using struct. It&rsquo;s safe to restart it, all rules will be regenerated
automatically during the first run.</p></li>

<li><p>it&rsquo;s watching events and looking for ingresses. If there is a new service it will be automatically added to the prometheus rules.</p></li>

<li><p>it can ADD new service, DELETE or EDIT it, depends on what type of event is it.</p></li>

<li><p>Just in case of any issues with events (which can be when some workers are going down, or any other networking issues), it&rsquo;s checking and re-generating ingress list every 5 minutes.</p></li>
</ul>

<p>There is no need for human interaction. Everything is doing an operator.</p>

<pre><code>________    ADD    ______________                _________________
| User | --------&gt; | NEW_SERVICE| &lt;-- [operator] --&gt; |PrometheusRules| --&gt; On the LIST (CREATED)
--------           --------------                -----------------

________  DELETE   ______________                _________________
| User | --------&gt; | NEW_SERVICE| &lt;-- [operator] --&gt; |PrometheusRules| --&gt; Not on the LIST (DELETED)
--------           --------------                -----------------

________  UPDATE   ______________                _________________
| User | --------&gt; | NEW_SERVICE| &lt;-- [operator] --&gt; |PrometheusRules| --&gt; On the LIST (MODIFIED)
--------           --------------                -----------------
</code></pre>

<p>We can modify rules by Annotations like:</p>

<pre><code>➜ operator git:(master) ✗ curl http://operator/service/dns-service | jq

{
  &quot;Name&quot;: &quot;dns-service&quot;,
  &quot;Namespace&quot;: &quot;webhook&quot;,
  &quot;Annotations&quot;: {
    &quot;operator_errors_critical&quot;: &quot;1&quot;,
    &quot;operator_errors_warning&quot;: &quot;5&quot;,
    &quot;operator_latency_critical&quot;: &quot;0.500&quot;,
    &quot;operator_latency_warning&quot;: &quot;1.000&quot;
  }
}
➜ operator git:(master) ✗

</code></pre>

<h2 id="rules">Rules</h2>

<p>Currently operator is using 2 rules:</p>

<pre><code>- `Errors` - number of errors in percentage for the last 2 minutes. Default warning `2%`, default critical `5%`.
Which means, that if we will get more then `2%` of 500 status code for all requests in the last 2 minutes we will
get a warning.

- `Latency` - Same idea as for Errors. We are checking here latency, default value is `0.500` which is 500ms, and
critical is `1.000`, 1000ms.
</code></pre>

<p>It&rsquo;s easy to add more rules, but the whole idea is to have less monitoring rules as possible.</p>

<p>And now a bit of code (golang!)</p>

<p>I like to keep all values in one struct that&rsquo;s why I created a struct similar to this:</p>

<pre><code>type application struct {
	kapi  kubeapi.KubeApiIface
	ingr  ingress.IngressIface
	srv   services.IFace
	prom  v1.PrometheusIface
	slack slack.SlackIFace
}
</code></pre>

<p>To create it we are using separate function:</p>

<pre><code>func newApplication() (*application, error) {
	kAPI, err := kubeapi.New()
	if err != nil {
		return &amp;application{}, err
	}

	return &amp;application{
		kapi:  kAPI,
		ingr:  ingress.New(kAPI.GetClientSet()),
		prom:  v1.New(kAPI.GetClientSetV1()),
		srv:   service.New()
		slack: slack.New(),
	}, nil
}
</code></pre>

<p>Every process, events, services, ingress, and creating struct is running on a different go-routine. To handle errors from them you can do something like this:</p>

<pre><code>exists, err := app.prom.Get()
	if err != nil {
		select {
			case outputChannel &lt;- IngressIterator{Ingress: nil, Err: err}:
				return
			}
	}
</code></pre>

<p>And simple struct:</p>

<pre><code>type IngressIterator struct {
	Ingress *ingress.Ingresses
	Err     error
}
</code></pre>

<p>Each module is using it&rsquo;s own interface to simplify writing tests and adding new functionality</p>

<pre><code>type IngressIface interface {
	GenNewList(c *kubernetes.Clientset) error
	GetAllFromStruct() *Ingresses
	Create(ing *v1beta1.Ingress)
	Update(ing *v1beta1.Ingress)
	Delete(ing *v1beta1.Ingress) error
	Exist(name string, namespace string) bool
}
</code></pre>

<p>This is how my watcher looks like:</p>

<pre><code>package watcher

import (
	metav1 &quot;k8s.io/apimachinery/pkg/apis/meta/v1&quot;
	&quot;k8s.io/apimachinery/pkg/watch&quot;
	&quot;k8s.io/client-go/kubernetes&quot;
)

func Watch(clientSet *kubernetes.Clientset) (watch.Interface, error) {
	watcher, err := clientSet.ExtensionsV1beta1().Ingresses(&quot;&quot;).Watch(metav1.ListOptions{})
	if err != nil {
		return nil, err
	}
	return watcher, err
}
</code></pre>

<p>And integration with the Slack:</p>

<pre><code>package slack

import (
	&quot;bytes&quot;
	&quot;encoding/json&quot;
	&quot;errors&quot;
	&quot;net/http&quot;
	&quot;time&quot;
)

const (
	WebHookURL = &quot;&quot;
)

type SlackIFace interface {
	SendSlackNotification(msg string) error
}

type SlackRequestBody struct {
	Text string `json:&quot;text&quot;`
}

func New() *SlackRequestBody {
	return &amp;SlackRequestBody{}
}

func (s *SlackRequestBody) SendSlackNotification(msg string) error {
	slackBody, _ := json.Marshal(SlackRequestBody{Text: msg})
	req, err := http.NewRequest(http.MethodPost, WebHookURL, bytes.NewBuffer(slackBody))
	if err != nil {
		return err
	}

	req.Header.Add(&quot;Content-Type&quot;, &quot;application/json&quot;)

	client := &amp;http.Client{Timeout: 10 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return err
	}

	buf := new(bytes.Buffer)
	buf.ReadFrom(resp.Body)
	if buf.String() != &quot;ok&quot; {
		return errors.New(&quot;Non-ok response returned from Slack&quot;)
	}
	return nil
}
</code></pre>

<p>Also, my ingress struct:</p>

<pre><code>type IngressIface interface {
	GenNewList(c *kubernetes.Clientset) error
	GetAllFromStruct() *Ingresses
	Create(ing *v1beta1.Ingress)
	Update(ing *v1beta1.Ingress)
	Delete(ing *v1beta1.Ingress) error
	Exist(name string, namespace string) bool
}
</code></pre>

<p>Rules struct:</p>

<pre><code>type RuleInterface interface {
	List(opts metav1.ListOptions) (*PrometheusRuleList, error)
	Get(name string, options metav1.GetOptions) (*PrometheusRule, error)
	Create(*PrometheusRule) (*PrometheusRule, error)
	Update(*PrometheusRule) (*PrometheusRule, error)
	Watch(opts metav1.ListOptions) (watch.Interface, error)
}
</code></pre>

<p>And this is how I&rsquo;m using register:</p>

<pre><code>package v1

import (
	metav1 &quot;k8s.io/apimachinery/pkg/apis/meta/v1&quot;
	&quot;k8s.io/apimachinery/pkg/runtime&quot;
	&quot;k8s.io/apimachinery/pkg/runtime/schema&quot;
)

var SchemeGroupVersion = schema.GroupVersion{Group: prometheus.GroupName, Version: prometheus.GroupVersion}

var (
	SchemeBuilder      runtime.SchemeBuilder
	localSchemeBuilder = &amp;SchemeBuilder
	AddToScheme        = localSchemeBuilder.AddToScheme
)

func init() {
	// We only register manually written functions here. The registration of the
	// generated functions takes place in the generated files. The separation
	// makes the code compile even when the generated files are missing.
	localSchemeBuilder.Register(addKnownTypes)
}

func addKnownTypes(scheme *runtime.Scheme) error {
	scheme.AddKnownTypes(SchemeGroupVersion,
		&amp;PrometheusRule{},
		&amp;PrometheusRuleList{},
	)

	metav1.AddToGroupVersion(scheme, SchemeGroupVersion)
	return nil
}

func Resource(resource string) schema.GroupResource {
	return SchemeGroupVersion.WithResource(resource).GroupResource()
}
</code></pre>

<p>Of course to call and modify PrometheusRules we need to register it to be able to call Custom Resource Definition.
Most of the metrics I&rsquo;m taking from the <code>nginx_ingress_controller_ingress_upstream_latency_seconds</code> and <code>nginx_ingress_controller_requests</code>.</p>

<p>And that&rsquo;s it. We have now out operator. We don&rsquo;t need to do more. Everytime when someone will add a new service our rules will be added automatically by our operator. Same for modifying it or deleting. The only time when we do something with it is it add more rules.</p>

<p>PS. I&rsquo;m using it on the production since 2 months, still all good :-)</p>

</div>


    </main>

    
  </body>
</html>
